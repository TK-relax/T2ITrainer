2025-08-08 09:32:47,899 - __main__ - INFO - 文件日志已配置。所有详细日志将被保存到: /root/shared-nvme/tiankuan/T2ITrainer/lora_model_test3/training_run.log
2025-08-08 09:32:47,906 - __main__ - INFO - 加载 VAE...
2025-08-08 09:32:48,513 - __main__ - INFO - 加载文本编码器以计算固定Prompt的嵌入...
2025-08-08 09:33:23,687 - __main__ - INFO - 正在为固定Prompt计算文本嵌入: 'Remove digital noise and grain, keep the composition unchanged'
2025-08-08 09:33:24,057 - __main__ - INFO - 文本嵌入计算完成，正在卸载文本编码器以节省VRAM...
2025-08-08 09:33:24,597 - __main__ - INFO - 文本编码器已卸载。
2025-08-08 09:33:24,598 - __main__ - INFO - 正在从 config.yaml 初始化数据加载器...
2025-08-08 09:33:24,601 - __main__ - INFO - --- 正在准备 'train' 数据加载器 ---
2025-08-08 09:33:25,947 - __main__ - INFO - --- 'train' 数据加载器准备就绪, 样本数: 76800 ---
2025-08-08 09:33:25,947 - __main__ - INFO - --- 正在准备 'validate' 数据加载器 ---
2025-08-08 09:33:25,971 - __main__ - INFO - --- 'validate' 数据加载器准备就绪, 样本数: 140 ---
2025-08-08 09:33:35,554 - __main__ - INFO - ***** Running training *****
2025-08-08 09:33:35,554 - __main__ - INFO -   Num examples = 76800
2025-08-08 09:33:35,554 - __main__ - INFO -   Num Epochs = 8
2025-08-08 09:33:35,554 - __main__ - INFO -   Instantaneous batch size per device = 4
2025-08-08 09:33:35,554 - __main__ - INFO -   Total train batch size (w. parallel, distributed & accumulation) = 4
2025-08-08 09:33:35,554 - __main__ - INFO -   Gradient Accumulation steps = 1
2025-08-08 09:33:35,554 - __main__ - INFO -   Total optimization steps = 153600
